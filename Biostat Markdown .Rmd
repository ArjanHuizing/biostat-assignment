---
title: "Biomedical Statistics"
author: "Katalin Roth, Anna Lohmann, Arjnan Huizing"
date: "3/22/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo = FALSE}
pre code, pre, code {
  white-space: pre !important;
  overflow-x: auto;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
```

<center> <h1>Introduction to Clinical Trials: Exercise 2</h1> </center>

Suppose an investigator wishes to conduct a trial to show superiority of a novel treatment E against some control treatment C. The outcome of interest is a dichotomous event, with *1* representing a negative outcome (e.g. all-cause mortality) and *0* representing a positive outcome, after a fixed follow-up duration. The investigator hopes to find that the event rate will drop from 0.4 to at least 0.35 when patients are treated with treatment E as opposed to treatment C. You are asked to determine the required sample size.

Assume that (1) the outcome is (in each group) binomially distributed, (2) trial dropout can be ignored, (3) the two groups are to be of equal size, (4) the test is to be performed one-sided with nominal type 1 error ??=0.025.

Although, in practice, you would most likely use a function such as the R function power.prop.test(), here we will use a simple simulation study to estimate the power (as well as the empirical type 1 error) for a range of sample sizes.

It generates 1000 samples for both treatment arms under the assumed alternative
hypothesis (note: feel free to increase numsim where necessary). Then, it
determines whether the null hypothesis is to be rejected or not. The proportion
of rejections equals the power, which is returned by the function. Make sure to
understand each of the commands in the function.

```{r}
f1 <- function(n, piE, piC, numsim = 1000){
  sE <- rbinom(numsim, n, piE)
  sC <- rbinom(numsim, n, piC)
  pvals <- sapply(1:numsim, FUN = function(i) prop.test(x = c(sE[i], sC[i]), n = c(n, n),
                                                        alternative = "less")$p.value)
  mean(pvals < 0.025)
}
```



#### Question 1
**Run f1() for n=100,200,300,...,2000. Store the output and plot the power curve. Note: warning messages due to low expected values can be ignored. Based on this initial assessment, how many subjects are (approximately) needed in each treatment arm to obtain a power of 0.80?**

```{r, message=FALSE}
piE <- 0.35
piC <- 0.4
seq(100, 2000, by=100)
y <- NULL
for (n in seq(100, 2000, by=100)){
 y[n] <- (f1(n, piE, piC, numsim = 1000))
  }

f1(100, piE, piC, numsim = 1000) #0.092
f1(200, piE, piC, numsim = 1000) #0.146
f1(300, piE, piC, numsim = 1000) #0.222

y <- y[seq(100, 2000, by=100)]
y
```

Our plot:

```{r}
plot(seq(100, 2000, by=100), y)
abline(h=0.8, col="red")
```


#### Question 2
**The function f1() can also be used to obtain the empirical type 1 error rate. Run f1() again, this time to determine the empirical type 1 error rate, for the same values of n. Again, generate a plot to visualize the results.**

```{r, message = FALSE}
z <- NULL
for (n in seq(100, 2000, by = 100)){
  z[n] <- (f1(n, 0.4, 0.4, numsim = 1000))
}
z <- z[seq(100, 2000, by = 100)]
z
```

And another plot:

```{r}
plot(seq(100, 2000, by = 100), z)
```


#### Question 3
**Now suppose that, for ethical and/or logistical reasons, the investigator wants to be able to halt the trial if the observed difference already is significant after observing the outcomes for half of the subjects (if it is not significant at that point, the trial is to be continued until all 2n subjects are included). Assuming that the same ?? of 0.025 is used in both tests? Adjust f1() to represent this sequential testing scenario, and repeat the exercises above. What would be the impact on the power and type 1 error?**

```{r, message=FALSE}
f2 <- function(n, piE, piC, numsim = 1000,alpha=0.025){
  sE <- rbinom(numsim, (0.5*n), piE)
  sC <- rbinom(numsim, (0.5*n), piC)
  pvals <- sapply(1:numsim, FUN = function(i) prop.test(x = c(sE[i], sC[i]), n = c((0.5*n), (0.5*n)),
                                                        alternative = "less")$p.value)
  
  n.signif <- mean(pvals < alpha)
  fulltrial <- sum((pvals > alpha) == TRUE)

  nonsig <- numeric(0)
  
  for(i in 1:numsim){
    if(pvals[i] < alpha){
     nonsig[i] <- 0
    }
    else{
     nonsig[i] <- 1
    }
  }
  
  r.sE <- nonsig*sE
  r.sE <- r.sE[!r.sE %in% 0]
  sE2 <- rbinom(fulltrial, (0.5*n), piE)
  sEt <- (r.sE+sE2)
  
  r.sC <- nonsig*sC
  r.sC <- r.sC[!r.sC %in% 0]
  sC2 <- rbinom(fulltrial, (0.5*n), piE)
  sCt <- (r.sC+sC2)

  
  pvals2 <- sapply(1:length(sEt), FUN = function(i) prop.test(x = c(sEt[i], sCt[i]), n = c(n, n),
                                                        alternative = "less")$p.value)
  n.signif.retrial <- mean(pvals2 < alpha)
  n.signif2 <- (n.signif.retrial*(fulltrial/numsim))
  
  n.signif+n.signif2
  
}

f2(1500, piE, piC, numsim = 1000) # 0.549
f1(1500, piE, piC, numsim = 1000) # 0.792
#power drops quite a bit..

piE <- 0.35
piC <- 0.4
seq(100,2000,by=100)
y <- NULL
for (n in seq(100,2000,by=100)){
  y[n] <- (f2(n, piE, piC, numsim = 1000))
}

y <- y[seq(100,2000,by=100)]
y
```

Guess what, one more plot!

```{r}
plot(seq(100, 2000, by = 100), y)
abline(h=0.8, col="red")
```


#### Question 4
**What is the impact of choosing ??=0.001 for the interim analysis (i.e. only halting the trial early if the evidence in favour of the experimental treatment is very clear)?**

```{r, message=FALSE}
piE <- 0.35
piC <- 0.4
seq(100,2000,by=100)
y <- NULL
for (n in seq(100,2000,by=100)){
  y[n] <- (f2(n, piE, piC, numsim = 1000,alpha=0.001))
}

y <- y[seq(100, 2000, by = 100)]
y
```

Okay, one last plot..

```{r}
plot(seq(100, 2000, by = 100), y)
abline(h=0.8, col="red")
```

