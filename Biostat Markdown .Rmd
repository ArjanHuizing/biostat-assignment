---
title: "Biomedical Statistics"
author: "Katalin Roth, Anna Lohmann, Arjan Huizing"
date: "3/22/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo = FALSE}
pre code, pre, code {
  white-space: pre !important;
  overflow-x: auto;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
```

<center> <h1>Introduction to Clinical Trials: Exercise 2</h1> </center>

Suppose an investigator wishes to conduct a trial to show superiority of a novel treatment E against some control treatment C. The outcome of interest is a dichotomous event, with *1* representing a negative outcome (e.g. all-cause mortality) and *0* representing a positive outcome, after a fixed follow-up duration. The investigator hopes to find that the event rate will drop from 0.4 to at least 0.35 when patients are treated with treatment E as opposed to treatment C. You are asked to determine the required sample size.

Assume that (1) the outcome is (in each group) binomially distributed, (2) trial dropout can be ignored, (3) the two groups are to be of equal size, (4) the test is to be performed one-sided with nominal type 1 error ??=0.025.

Although, in practice, you would most likely use a function such as the R function power.prop.test(), here we will use a simple simulation study to estimate the power (as well as the empirical type 1 error) for a range of sample sizes.

It generates 1000 samples for both treatment arms under the assumed alternative
hypothesis (note: feel free to increase numsim where necessary). Then, it
determines whether the null hypothesis is to be rejected or not. The proportion
of rejections equals the power, which is returned by the function. Make sure to
understand each of the commands in the function.

```{r}
f1 <- function(n, piE, piC, numsim = 1000){
  sE <- rbinom(numsim, n, piE)
  sC <- rbinom(numsim, n, piC)
  pvals <- sapply(1:numsim, FUN = function(i) prop.test(x = c(sE[i], sC[i]), n = c(n, n),
                                                        alternative = "less")$p.value)
  mean(pvals < 0.025)
}
```



#### Question 1
**Run f1() for n=100,200,300,...,2000. Store the output and plot the power curve. Note: warning messages due to low expected values can be ignored. Based on this initial assessment, how many subjects are (approximately) needed in each treatment arm to obtain a power of 0.80?**

First we define an input. Since the power is defined as the probability that we will reject a false null hypothesis. We have to set the input such that the alternative hypothesis is true.

```{r, results ='hide'}
piE <- 0.35
piC <- 0.4
numbs <- seq(100, 2000, by=100) # defines our sequence for n = (100,200,300,...2000)
y <- NULL
```


Then we run the given function to determine the power.

```{r, results ='hide'}
set.seed(42) # we set a seed so we can fairly compare each simulation
for (n in numbs){
 y[n] <- (f1(n, piE, piC, numsim = 1000))
}

y <- y[numbs]
```

The following plot depicts the power depending on the sample size in each arm of the trial

```{r}
plot(numbs, y)
abline(h=0.8, col="red")
```

The red line represents where we expect a power of about .80. This is the case with about 1500 participants.

#### Question 2
**The function f1() can also be used to obtain the empirical type 1 error rate. Run f1() again, this time to determine the empirical type 1 error rate, for the same values of n. Again, generate a plot to visualize the results.**

The type 1 error is the incorrect rejection of a true null hypothesis. Hence, if the null hypothesis is true piE must be the sam as piC, so both 0.4.

```{r, results ='hide'}
z <- NULL
set.seed(42)
for (n in numbs){
  z[n] <- (f1(n, 0.4, 0.4, numsim = 1000))
}
z <- z[numbs]
```

This plot shows our type 1 error depending on the sample size.

```{r}
plot(numbs, z)
```


#### Question 3
**Now suppose that, for ethical and/or logistical reasons, the investigator wants to be able to halt the trial if the observed difference already is significant after observing the outcomes for half of the subjects (if it is not significant at that point, the trial is to be continued until all 2n subjects are included). Assuming that the same ?? of 0.025 is used in both tests? Adjust f1() to represent this sequential testing scenario, and repeat the exercises above. What would be the impact on the power and type 1 error?**

```{r}
f2 <- function(n, piE, piC, numsim = 1000, alpha=0.025){
  sE <- rbinom(numsim, (0.5*n), piE) # We only use half the n in each step.
  sC <- rbinom(numsim, (0.5*n), piC)
  pvals <- sapply(1:numsim, FUN = function(i) prop.test(x = c(sE[i], sC[i]), n = c((0.5*n), (0.5*n)),
                                                        alternative = "less")$p.value)
  
  n.signif <- mean(pvals < alpha) # percentage of significant p-values
  fulltrial <- sum((pvals > alpha) == TRUE) # number of insignificant p-values

  nonsig <- numeric(0)
  
  for(i in 1:numsim){
    if(pvals[i] < alpha){
     nonsig[i] <- 0 # if the p-value is significant the indicator is set to zero
    }
    else{
     nonsig[i] <- 1 #if it is not the the indicator is set to 1
    }
  }
  
  r.sE <- nonsig*sE # define a vector with only the non-significant cases
  r.sE <- r.sE[!r.sE %in% 0] # chose only the unsignificant cases
  sE2 <- rbinom(fulltrial, (0.5*n), piE) # simulate the second half of the non-significant trial
  sEt <- (r.sE+sE2)# combiningthe halves
  
  # same procedure for the control groups
  r.sC <- nonsig*sC
  r.sC <- r.sC[!r.sC %in% 0]
  sC2 <- rbinom(fulltrial, (0.5*n), piE)
  sCt <- (r.sC+sC2)
  
  pvals2 <- sapply(1:length(sEt), FUN = function(i) prop.test(x = c(sEt[i], sCt[i]), n = c(n, n),
                                                        alternative = "less")$p.value)
  n.signif.retrial <- mean(pvals2 < alpha)
  n.signif2 <- (n.signif.retrial*(fulltrial/numsim))
  
  n.signif + n.signif2
}

set.seed(42)
f2(1500, piE, piC, numsim = 1000) # 0.549
f1(1500, piE, piC, numsim = 1000) # 0.792
# power drops quite a bit..

piE <- 0.35
piC <- 0.4
y <- NULL
for (n in numbs){
  y[n] <- (f2(n, piE, piC, numsim = 1000))
}

y <- y[numbs]
y
```


Write answer here...

#### Question 4
**What is the impact of choosing ??=0.001 for the interim analysis (i.e. only halting the trial early if the evidence in favour of the experimental treatment is very clear)?**

```{r, results ='hide'}
piE <- 0.35
piC <- 0.4
y <- NULL

set.seed(42)
for (n in numbs){
  y[n] <- (f2(n, piE, piC, numsim = 1000,alpha=0.001))
}

y <- y[numbs]
y
```


Write answer here..